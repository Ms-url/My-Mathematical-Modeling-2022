% % % % % % % % % % % % % % % % 评价回归结果：
% % 均方误差MSE（mse）
%       测试集中的数据量m不同，因为有累加操作，所以随着数据的增加 ，误差会逐渐积累；
%       因此衡量标准和m相关。为了抵消掉数据量的形象，可以除去数据量，抵消误差。
%       通过这种处理方式得到的结果叫做均方误差MSE（Mean Squared Error）：

% % 均方根误差RMSE（rmse）
%       使用均方误差MSE收到量纲的影响。
%       例如在衡量房产时，y的单位是（万元），那么衡量标准得到的结果是（万元平方）。
%       为了解决量纲的问题，可以将其开方（为了解决方差的量纲问题，将其开方得到平方差）
%       得到均方根误差RMSE（Root Mean Squarde Error）：
%       平均绝对误差MAE（mae）

% % 平均绝对误差MAE
%       对于线性回归算法还有另外一种非常朴素评测标准。
%       要求真实值 与 预测结果 之间的距离最小，可以直接相减做绝对值，加m次再除以m，
%       即可求出平均距离，被称作平均绝对误差MAE（Mean Absolute Error）：

% 中位绝对误差(MedAE, Median Absolute Error)
%       通过取目标和预测之间的所有绝对差值的中值来计算损失.

% 平均绝对百分比误差(MAPE, Mean Absolute Percentage Error)
%       这个指标是对相对误差损失的预期值.所谓相对误差,就是绝对误差和真值的百分比.
%           MAPE = sum( abs(y1-y0)./y1 )/ n;

% % R square
%       事实上，新增加一个变量，R2会加大，当自变量足够多，模型预测效果会变好，而实际却并非如此；
%       所以单独用来评价模型的好坏并不靠谱。于是考虑调整R方

% 调整 R square
%       当给模型增加自变量时，复决定系数也随之逐步增大，当自变量足够多时总会得到模型拟合良好，而
%       实际却可能并非如此。于是考虑对R2进行调整，记为Ra2, 称调整后复决定系数。

% % % % % % % % R方总是大于调整R方的且调整R方可能为负；
% % % % % % % % 并且只有R方趋近1时，调整R方才有出马的意义！


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% % % % % % % % % % % % % % % % %       各个评价指标的对比和使用

% 以上提到的度量,除了R Squared,都是越小越好. 使用哪种取决于目标,多种度量综合考虑则允许我们更深入得分析模型.
% 
% 单个指标使用的情况
% 
% （1）MAE 和 MedAE基于绝对误差,如果看重真实值和预测值的绝对误差,则选用MAE或MedAE,两者分别是误差的均值和中位数.MAE对极端值比较敏感.
% （2）如果看重真实值和预测值的差的平方,则选用MSE或RMSE.
% （3）如果存在不同样本的真实值有量级差或者更加关注预测和真实值的百分比差异的情况,最好选用MAPE.
% （4）如果y具有随着x进行指数变动的趋势时,适合用MSLE.recall that log（x+1） 是x的等阶无穷小和对x的对数化处理.
% （5）如果模型希望的是找到能够解释目标y变动的因变量,则选用R Squared更合适.
% 
% 多个指标配合使用的情况
% 
% MAE和RMSE一起使用,可以看出样本误差的离散程度.比如RMSE远大于MAE时,可以得知不同样例的误差差别很大.
% MAE和MAPE一起使用,再结合mean(y),可以估算模型对不同数量级样例的拟合程度.比如MAE远大于MAPE*mean(y)则可能是模型对真实值小的样本预测更准.可以考虑为不同数量级的样本建立不同的模型.



% % % % % % % % 评价多元回归模型
% 多元线性回归模型是一种简单而且有效的数学模型，一直在各领域广泛使用。一个多元回归模型建好后，如何评价模型的优劣呢？
% 1. F值检验
% 因变量的总变异(数据与均值之差的平方和，记为SStotal)由回归平方和(因变量的变异中可以由自变量解释的部分，记为SSR)与误差平方和(记为SSE)构成，如果自变量引起的变异大于随机误差引起的变异，则说明因变量与至少一个自变量存在线性关系。回归平方和与误差平方和的比值记为F，F值服从F分布，通过查F分布概率表可得F值对应的概率，从而判断是否存在统计学意义。F值越大越好。
% 
% 2. 偏回归系数检验
% 通过了F检验只说明因变量至少和一个自变量存在线性关系，但不是所有x都跟y存在线性关系。对每个变量的回归系数分别作t检验，假设回归系数为0，得到的概率值越小越好，一般取0.05作为临界值。
% 
% 3. 标准化偏回归系数
% y和x均经过标准化，均值为0，标准差为1，此时的回归结果常数项为0.消除了量纲的影响，更能直观表示自变量对因变量的影响。如果某项回归系数接近0，则说明该自变量与因变量的不具有线性关系，应当剔除。
% 
% 4. 复相关系数R
% 指的是因变量与因变量的估计值(回归后得出的值)之间的简单线性相关系数，范围在0-1之间，一般来说，R值应大于0.9，但在某些社会科学研究中只要求R大于0.4，这是因为在社会科学研究中存在大量对因变量有影响却无法进行量化的因数，无法纳入模型研究。值得注意的是，即使向模型增加的变量没有统计学意义，R值也会增加，所以R值只作为参考。
% 
% 5. 决定系数R2
% 因变量总变异中由模型中自变量解释部分的比例。也是越大越好，但是存在与R同样的问题。
% R2=SSR/SStotal=1-SSE/SStotal
% 
% 6.校正的决定系数R2adj
% 将自变量的个数纳入了考量范围，解决了R2 的局限性，不会随着自变量的增加而增加。当模型中增加的自变量缺乏统计学意义时，校正的决定系数会减小。该项系数越大越好。
% R2adj=1-(n-1)(1- R2)/(n-p-1) n表示样本量，p表示模型中自变量个数
% 
% 7.剩余标准差
% 误差均方的算术平方根，该值应明显小于因变量的标准差，越小越好。说明在引入模型自变量后，因变量的变异明显减小。
% 
% 8. 赤池信息准则AIC
% 包含两部分，一部分反映拟合精度，一部分反映模型繁简程度(自变量个数越少模型越简洁)，该值越小越好。值得注意的是，用最小二乘法拟合模型与用最大似然估计拟合的模型，其AIC计算方法是不一样的，所以用AIC进行模型比较时应注意拟合的方法是相同的才行。
% 最小二乘法拟合时：AIC=nln(SSE/n)+2p
% 最大似然估计拟合时：AIC=-2ln(L)+2p L为模型的最大似然函数
% 
% 以上8种数据很多统计软件都能方便地输出。